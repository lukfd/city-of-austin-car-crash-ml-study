{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Austin's Car Crash\n",
    "#### By: Luca Comba, Hung Tran, Steven Tran\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/a/a0/Seal_of_Austin%2C_TX.svg/1024px-Seal_of_Austin%2C_TX.svg.png\" width=\"100\" height=\"100\">\n",
    "\n",
    "#### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Data](#data)\n",
    "3. [Models](#models)\n",
    "4. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<div id=\"introduction\" />\n",
    "\n",
    "The original dataset includes records of traffic accidents in Austin, Texas, from 2010 to today, with 216,088 instances and 45 features, including both numerical and categorical data. The dataset can be found at [Austin Crash Report Data](https://catalog.data.gov/dataset/vision-zero-crash-report-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "<div id=\"data\" />\n",
    "\n",
    "In the following section we will set up the dataset and the features we will be using for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from utils.utils import (\n",
    "    print_linear_regression_scores,\n",
    "    backwards_elimination,\n",
    "    Timer,\n",
    "    Pickler\n",
    ")\n",
    "\n",
    "RANDOM_SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/austin_car_crash_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We went over the dataset cleansing in the file [cleaning.ipynb](./cleaning.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We went over the exploratory data analysis in the file [exploratory.ipynb](./exploratory.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "<div id=\"feature-selection\" />\n",
    "\n",
    "We ran the [feature_selection.ipynb](./feature_selection.ipynb) notebook for a preview run on the data, and now we will need to drop some features from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dropping the `primary_address`, `secondary_address`, `latitude`, `longitude`, and `timestamp_us_central` due to their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['primary_address', 'secondary_address', 'timestamp_us_central', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data split we will be using the **Backward Elimination** method for dropping unsatisfactory features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'estimated_total_comprehensive_cost'\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop(columns=[target_col]).astype(int)\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70-30 train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['month', 'construction_zone', 'unit_involved_large_passenger_vehicle', 'month_sin', 'day_of_month', 'unit_involved_pedestrian', 'day_of_week', 'severity_possible_injury', 'severity_incapacitating_injury', 'severity_non_incapacitating_injury', 'law_enforcement_fatality_count', 'unit_involved_bicycle', 'year', 'death_cnt', 'tot_injry_cnt', 'unit_involved_passenger_car', 'month_cos', 'hour_sin', 'unit_involved_other_unknown']\n"
     ]
    }
   ],
   "source": [
    "X_train, backwards_eliminated_features = backwards_elimination(X_train, y_train)\n",
    "print(f\"Removed features: {backwards_eliminated_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before backwards elimination: 47\n",
      "Number of features after backwards elimination train: 27\n",
      "Number of features after backwards elimination test: 27\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features before backwards elimination: {len(df.columns)}\")\n",
    "\n",
    "X_train = X_train.drop(columns = ['const'])\n",
    "X_test = X_test.drop(columns = backwards_eliminated_features)\n",
    "\n",
    "print(f\"Number of features after backwards elimination train: {len(X_train.columns)}\")\n",
    "print(f\"Number of features after backwards elimination test: {len(X_test.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after backwards elimination: ['fatal_crash', 'speed_limit', 'sus_serious_injry_cnt', 'nonincap_injry_cnt', 'poss_injry_cnt', 'non_injry_cnt', 'unkn_injry_cnt', 'motor_vehicle_death_count', 'motor_vehicle_serious_injury_count', 'bicycle_death_count', 'bicycle_serious_injury_count', 'pedestrian_death_count', 'pedestrian_serious_injury_count', 'motorcycle_death_count', 'motorcycle_serious_injury_count', 'other_death_count', 'other_serious_injury_count', 'micromobility_serious_injury_count', 'micromobility_death_count', 'severity_killed', 'severity_not_injured', 'severity_unknown', 'unit_involved_motor_vehicle_other', 'unit_involved_motorcycle', 'hour', 'weekend', 'hour_cos']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features after backwards elimination: {X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['fatal_crash', 'speed_limit', 'sus_serious_injry_cnt', 'nonincap_injry_cnt', 'poss_injry_cnt', 'non_injry_cnt', 'unkn_injry_cnt', 'motor_vehicle_death_count', 'motor_vehicle_serious_injury_count', 'bicycle_death_count', 'bicycle_serious_injury_count', 'pedestrian_death_count', 'pedestrian_serious_injury_count', 'motorcycle_death_count', 'motorcycle_serious_injury_count', 'other_death_count', 'other_serious_injury_count', 'micromobility_serious_injury_count', 'micromobility_death_count', 'severity_killed', 'severity_not_injured', 'severity_unknown', 'unit_involved_motor_vehicle_other', 'unit_involved_motorcycle', 'hour', 'weekend', 'hour_cos']\n"
     ]
    }
   ],
   "source": [
    "# Select numeric columns\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns: {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [ 'unit_involved_motor_vehicle_other', 'unit_involved_motorcycle']\n",
    "\n",
    "# 'unit_involved_bicycle',\n",
    "# 'unit_involved_large_passenger_vehicle',\n",
    "# 'unit_involved_motor_vehicle_other',\n",
    "# 'unit_involved_motorcycle',\n",
    "# 'unit_involved_other_unknown',\n",
    "# 'unit_involved_passenger_car',\n",
    "# 'unit_involved_pedestrian',\n",
    "\n",
    "for col in cols_to_remove:\n",
    "    numeric_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: []\n"
     ]
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train after scaler. mean: fatal_crash                            0.005536\n",
      "speed_limit                           45.898879\n",
      "sus_serious_injry_cnt                  0.035196\n",
      "nonincap_injry_cnt                     0.284108\n",
      "poss_injry_cnt                         0.359067\n",
      "non_injry_cnt                          1.846197\n",
      "unkn_injry_cnt                         0.109186\n",
      "motor_vehicle_death_count              0.002808\n",
      "motor_vehicle_serious_injury_count     0.024529\n",
      "bicycle_death_count                    0.000126\n",
      "bicycle_serious_injury_count           0.001866\n",
      "pedestrian_death_count                 0.001767\n",
      "pedestrian_serious_injury_count        0.003598\n",
      "motorcycle_death_count                 0.000915\n",
      "motorcycle_serious_injury_count        0.005186\n",
      "other_death_count                      0.000000\n",
      "other_serious_injury_count             0.000018\n",
      "micromobility_serious_injury_count     0.000000\n",
      "micromobility_death_count              0.000000\n",
      "severity_killed                        0.005536\n",
      "severity_not_injured                   0.471663\n",
      "severity_unknown                       0.069029\n",
      "hour                                  12.873803\n",
      "weekend                                0.261159\n",
      "hour_cos                              -0.033285\n",
      "dtype: float64 std: fatal_crash                            0.074195\n",
      "speed_limit                           12.658144\n",
      "sus_serious_injry_cnt                  0.216012\n",
      "nonincap_injry_cnt                     0.641482\n",
      "poss_injry_cnt                         0.755973\n",
      "non_injry_cnt                          1.655607\n",
      "unkn_injry_cnt                         0.384439\n",
      "motor_vehicle_death_count              0.057469\n",
      "motor_vehicle_serious_injury_count     0.185634\n",
      "bicycle_death_count                    0.011207\n",
      "bicycle_serious_injury_count           0.059727\n",
      "pedestrian_death_count                 0.042429\n",
      "pedestrian_serious_injury_count        0.060469\n",
      "motorcycle_death_count                 0.030532\n",
      "motorcycle_serious_injury_count        0.073308\n",
      "other_death_count                      0.000000\n",
      "other_serious_injury_count             0.004236\n",
      "micromobility_serious_injury_count     0.000000\n",
      "micromobility_death_count              0.000000\n",
      "severity_killed                        0.074195\n",
      "severity_not_injured                   0.499196\n",
      "severity_unknown                       0.253503\n",
      "hour                                   5.994710\n",
      "weekend                                0.439266\n",
      "hour_cos                               0.283439\n",
      "dtype: float64\n",
      "Test after scaler. mean: fatal_crash                            0.006134\n",
      "speed_limit                           45.907683\n",
      "sus_serious_injry_cnt                  0.034436\n",
      "nonincap_injry_cnt                     0.282123\n",
      "poss_injry_cnt                         0.362885\n",
      "non_injry_cnt                          1.857002\n",
      "unkn_injry_cnt                         0.112414\n",
      "motor_vehicle_death_count              0.003517\n",
      "motor_vehicle_serious_injury_count     0.024325\n",
      "bicycle_death_count                    0.000188\n",
      "bicycle_serious_injury_count           0.001675\n",
      "pedestrian_death_count                 0.001968\n",
      "pedestrian_serious_injury_count        0.003684\n",
      "motorcycle_death_count                 0.000963\n",
      "motorcycle_serious_injury_count        0.004752\n",
      "other_death_count                      0.000000\n",
      "other_serious_injury_count             0.000000\n",
      "micromobility_serious_injury_count     0.000000\n",
      "micromobility_death_count              0.000000\n",
      "severity_killed                        0.006134\n",
      "severity_not_injured                   0.472116\n",
      "severity_unknown                       0.069918\n",
      "hour                                  12.959912\n",
      "weekend                                0.262340\n",
      "hour_cos                              -0.034771\n",
      "dtype: float64 std: fatal_crash                            0.078076\n",
      "speed_limit                           12.720562\n",
      "sus_serious_injry_cnt                  0.212463\n",
      "nonincap_injry_cnt                     0.688809\n",
      "poss_injry_cnt                         0.763167\n",
      "non_injry_cnt                          1.744036\n",
      "unkn_injry_cnt                         0.398929\n",
      "motor_vehicle_death_count              0.068387\n",
      "motor_vehicle_serious_injury_count     0.186735\n",
      "bicycle_death_count                    0.013725\n",
      "bicycle_serious_injury_count           0.040889\n",
      "pedestrian_death_count                 0.046167\n",
      "pedestrian_serious_injury_count        0.062290\n",
      "motorcycle_death_count                 0.031684\n",
      "motorcycle_serious_injury_count        0.071457\n",
      "other_death_count                      0.000000\n",
      "other_serious_injury_count             0.000000\n",
      "micromobility_serious_injury_count     0.000000\n",
      "micromobility_death_count              0.000000\n",
      "severity_killed                        0.078076\n",
      "severity_not_injured                   0.499222\n",
      "severity_unknown                       0.255009\n",
      "hour                                   5.993700\n",
      "weekend                                0.439907\n",
      "hour_cos                               0.286360\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Train after scaler. mean: {np.mean(X_train[numeric_cols], axis=0)} std: {np.std(X_train[numeric_cols], axis=0)}')\n",
    "print(f'Test after scaler. mean: {np.mean(X_test[numeric_cols], axis=0)} std: {np.std(X_test[numeric_cols], axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train after scaler. mean: fatal_crash                          -3.072659e-17\n",
      "speed_limit                           1.296636e-16\n",
      "sus_serious_injry_cnt                -3.273465e-17\n",
      "nonincap_injry_cnt                   -2.996161e-18\n",
      "poss_injry_cnt                        6.279188e-17\n",
      "non_injry_cnt                        -3.056722e-17\n",
      "unkn_injry_cnt                       -1.491706e-17\n",
      "motor_vehicle_death_count             6.374810e-18\n",
      "motor_vehicle_serious_injury_count   -3.773888e-17\n",
      "bicycle_death_count                  -1.211214e-18\n",
      "bicycle_serious_injury_count          2.613672e-18\n",
      "pedestrian_death_count               -7.267284e-18\n",
      "pedestrian_serious_injury_count       2.476614e-17\n",
      "motorcycle_death_count                4.844856e-18\n",
      "motorcycle_serious_injury_count       2.722044e-17\n",
      "other_death_count                     0.000000e+00\n",
      "other_serious_injury_count           -7.012291e-19\n",
      "micromobility_serious_injury_count    0.000000e+00\n",
      "micromobility_death_count             0.000000e+00\n",
      "severity_killed                      -3.072659e-17\n",
      "severity_not_injured                  2.766668e-17\n",
      "severity_unknown                     -2.804917e-17\n",
      "hour                                  6.374810e-19\n",
      "weekend                               1.512105e-16\n",
      "hour_cos                              2.537175e-17\n",
      "dtype: float64 std: fatal_crash                           1.0\n",
      "speed_limit                           1.0\n",
      "sus_serious_injry_cnt                 1.0\n",
      "nonincap_injry_cnt                    1.0\n",
      "poss_injry_cnt                        1.0\n",
      "non_injry_cnt                         1.0\n",
      "unkn_injry_cnt                        1.0\n",
      "motor_vehicle_death_count             1.0\n",
      "motor_vehicle_serious_injury_count    1.0\n",
      "bicycle_death_count                   1.0\n",
      "bicycle_serious_injury_count          1.0\n",
      "pedestrian_death_count                1.0\n",
      "pedestrian_serious_injury_count       1.0\n",
      "motorcycle_death_count                1.0\n",
      "motorcycle_serious_injury_count       1.0\n",
      "other_death_count                     0.0\n",
      "other_serious_injury_count            1.0\n",
      "micromobility_serious_injury_count    0.0\n",
      "micromobility_death_count             0.0\n",
      "severity_killed                       1.0\n",
      "severity_not_injured                  1.0\n",
      "severity_unknown                      1.0\n",
      "hour                                  1.0\n",
      "weekend                               1.0\n",
      "hour_cos                              1.0\n",
      "dtype: float64\n",
      "Test after scaler. mean: fatal_crash                           0.008060\n",
      "speed_limit                           0.000695\n",
      "sus_serious_injry_cnt                -0.003520\n",
      "nonincap_injry_cnt                   -0.003095\n",
      "poss_injry_cnt                        0.005050\n",
      "non_injry_cnt                         0.006526\n",
      "unkn_injry_cnt                        0.008395\n",
      "motor_vehicle_death_count             0.012332\n",
      "motor_vehicle_serious_injury_count   -0.001098\n",
      "bicycle_death_count                   0.005604\n",
      "bicycle_serious_injury_count         -0.003205\n",
      "pedestrian_death_count                0.004722\n",
      "pedestrian_serious_injury_count       0.001433\n",
      "motorcycle_death_count                0.001567\n",
      "motorcycle_serious_injury_count      -0.005917\n",
      "other_death_count                     0.000000\n",
      "other_serious_injury_count           -0.004236\n",
      "micromobility_serious_injury_count    0.000000\n",
      "micromobility_death_count             0.000000\n",
      "severity_killed                       0.008060\n",
      "severity_not_injured                  0.000909\n",
      "severity_unknown                      0.003510\n",
      "hour                                  0.014364\n",
      "weekend                               0.002690\n",
      "hour_cos                             -0.005241\n",
      "dtype: float64 std: fatal_crash                           1.052312e+00\n",
      "speed_limit                           1.004931e+00\n",
      "sus_serious_injry_cnt                 9.835659e-01\n",
      "nonincap_injry_cnt                    1.073777e+00\n",
      "poss_injry_cnt                        1.009516e+00\n",
      "non_injry_cnt                         1.053412e+00\n",
      "unkn_injry_cnt                        1.037692e+00\n",
      "motor_vehicle_death_count             1.189978e+00\n",
      "motor_vehicle_serious_injury_count    1.005931e+00\n",
      "bicycle_death_count                   1.224694e+00\n",
      "bicycle_serious_injury_count          6.845974e-01\n",
      "pedestrian_death_count                1.088099e+00\n",
      "pedestrian_serious_injury_count       1.030120e+00\n",
      "motorcycle_death_count                1.037725e+00\n",
      "motorcycle_serious_injury_count       9.747525e-01\n",
      "other_death_count                     0.000000e+00\n",
      "other_serious_injury_count            8.673617e-19\n",
      "micromobility_serious_injury_count    0.000000e+00\n",
      "micromobility_death_count             0.000000e+00\n",
      "severity_killed                       1.052312e+00\n",
      "severity_not_injured                  1.000051e+00\n",
      "severity_unknown                      1.005943e+00\n",
      "hour                                  9.998315e-01\n",
      "weekend                               1.001458e+00\n",
      "hour_cos                              1.010307e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Train after scaler. mean: {np.mean(X_train[numeric_cols], axis=0)} std: {np.std(X_train[numeric_cols], axis=0)}')\n",
    "print(f'Test after scaler. mean: {np.mean(X_test[numeric_cols], axis=0)} std: {np.std(X_test[numeric_cols], axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "<div id=\"models\" />\n",
    "We will be using the following models:\n",
    "\n",
    "To predict the `estimated_total_comprehensive_cost` we can use:\n",
    "1. Linear Regression\n",
    "2. Ridge Regression\n",
    "3. Lasso Regression\n",
    "4. Decision Tree Regression\n",
    "5. Random Forest Regression\n",
    "6. Support Vector Regression (SVR)\n",
    "7. K-Nearest Neighbors (KNN) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "The sklearn pipeline will help us creating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = None # No preprocessing needed yet, usually we can run feature scaling and feature selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear_regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ]),\n",
    "    \"ridge_regression\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    \"lasso_regression\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', Lasso(alpha=0.1))\n",
    "    ]),\n",
    "    \"decision_tree_regressor\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', DecisionTreeRegressor(random_state=RANDOM_SEED))\n",
    "    ]),\n",
    "    \"random_forest_regressor\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1))\n",
    "    ]),\n",
    "    # SVR needs a better hardware\n",
    "    \"svr\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', SVR(kernel='rbf', C=1.0, epsilon=0.1))\n",
    "    ]),\n",
    "    \"k_neighbors_regressor\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', KNeighborsRegressor(n_neighbors=90, n_jobs=-1))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for hyperparameters tuning\n",
    "\n",
    "We will be using the `GridSearchCV` method to find the best hyperparameters for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'linear_regression': {},\n",
    "    'ridge_regression': {\n",
    "        'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    'lasso_regression': {\n",
    "        'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "    }, \n",
    "    'decision_tree_regressor': {\n",
    "        'regressor__max_depth': [3,5,10],                         \n",
    "        'regressor__min_samples_split':[2,5,10]\n",
    "    },\n",
    "    'random_forest_regressor': {\n",
    "        'regressor__n_estimators':[50, 100, 200],\n",
    "        'regressor__max_depth':[3,5,10]\n",
    "    }, \n",
    "    'srv': {\n",
    "        'regressor__C': [0.1, 1.0, 10.0], # penalty parameter\n",
    "        'regressor__epsilon': [0.1, 0.2, 0.5], # no pentaly if error is within epsilon\n",
    "        'regressor__kernel': ['linear', 'rbf']\n",
    "    }, \n",
    "    'k_neighbors_regressor': {\n",
    "        'regressor__n_neighbors': [3,5,10], # how many neighbors to look at \n",
    "        'regressor__weights': ['uniform', 'distance'] # how to weight neighbors\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_gridsearch = {}\n",
    "\n",
    "for model_name, model_pipeline in models.items(): \n",
    "    param_grid = param_grids.get(model_name, {})\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = model_pipeline, \n",
    "        param_grid = param_grid, \n",
    "        cv = 5, \n",
    "        n_jobs = -1, \n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    models_with_gridsearch[model_name] = grid_search\n",
    "\n",
    "# print(f\"Models with grid search:\\n {models_with_gridsearch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting linear_regression with GridSearchCV\n",
      "Executed in 3.1392 seconds\n",
      "linear_regression Scores:\n",
      "MAE: 583.0506 MSE: 4299908.8781 RMSE: 2073.6222 RMSE%: 0.67% R^2: 1.0000\n",
      "Best params for linear_regression: {}\n",
      "Best score for linear_regression: -5660958.989071017\n",
      "\n",
      "Fitting ridge_regression with GridSearchCV\n",
      "Executed in 1.1962 seconds\n",
      "ridge_regression Scores:\n",
      "MAE: 583.1215 MSE: 4300271.0105 RMSE: 2073.7095 RMSE%: 0.67% R^2: 1.0000\n",
      "Best params for ridge_regression: {'regressor__alpha': 0.1}\n",
      "Best score for ridge_regression: -5661019.368883605\n",
      "\n",
      "Fitting lasso_regression with GridSearchCV\n",
      "Executed in 1.9785 seconds\n",
      "lasso_regression Scores:\n",
      "MAE: 590.8319 MSE: 4480801.3493 RMSE: 2116.7903 RMSE%: 0.68% R^2: 1.0000\n",
      "Best params for lasso_regression: {'regressor__alpha': 0.1}\n",
      "Best score for lasso_regression: -5742671.113162955\n",
      "\n",
      "Fitting decision_tree_regressor with GridSearchCV\n",
      "Executed in 2.7308 seconds\n",
      "decision_tree_regressor Scores:\n",
      "MAE: 4532.7669 MSE: 6427155147.2742 RMSE: 80169.5400 RMSE%: 25.92% R^2: 0.9889\n",
      "Best params for decision_tree_regressor: {'regressor__max_depth': 10, 'regressor__min_samples_split': 2}\n",
      "Best score for decision_tree_regressor: -6339332426.443773\n",
      "\n",
      "Fitting random_forest_regressor with GridSearchCV\n",
      "Executed in 44.5197 seconds\n",
      "random_forest_regressor Scores:\n",
      "MAE: 4545.3615 MSE: 7064741530.3425 RMSE: 84052.0168 RMSE%: 27.18% R^2: 0.9878\n",
      "Best params for random_forest_regressor: {'regressor__max_depth': 10, 'regressor__n_estimators': 100}\n",
      "Best score for random_forest_regressor: -10422090059.329859\n",
      "\n",
      "Fitting svr with GridSearchCV\n",
      "Executed in 1585.4066 seconds\n",
      "svr Scores:\n",
      "MAE: 260758.6596 MSE: 625928268633.1140 RMSE: 791156.2858 RMSE%: 255.83% R^2: -0.0780\n",
      "Best params for svr: {}\n",
      "Best score for svr: -581791832053.0035\n",
      "\n",
      "Fitting k_neighbors_regressor with GridSearchCV\n",
      "Executed in 46.9306 seconds\n",
      "k_neighbors_regressor Scores:\n",
      "MAE: 3573.4560 MSE: 9430179021.7693 RMSE: 97109.1089 RMSE%: 31.40% R^2: 0.9838\n",
      "Best params for k_neighbors_regressor: {'regressor__n_neighbors': 3, 'regressor__weights': 'distance'}\n",
      "Best score for k_neighbors_regressor: -15149941256.865072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for model_name, grid_search in models_with_gridsearch.items(): \n",
    "    print(f\"Fitting {model_name} with GridSearchCV\")\n",
    "    with Timer():\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_hat = grid_search.predict(X_test)\n",
    "\n",
    "    metrics_dict = print_linear_regression_scores(model_name, y_test, y_hat)\n",
    "    print(f'Best params for {model_name}: {grid_search.best_params_}')\n",
    "    print(f'Best score for {model_name}: {grid_search.best_score_}')\n",
    "    print()\n",
    "    results[model_name] = {\n",
    "        \"y_hat\": y_hat, \n",
    "        \"params\": grid_search.best_params_, \n",
    "        \"scores\": grid_search.best_score_, \n",
    "        **metrics_dict\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "We will be using the `GridSearchCV` method to find the best hyperparameters for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ridge_regression regressor__alpha to 0.1\n",
      "Setting lasso_regression regressor__alpha to 0.1\n",
      "Setting decision_tree_regressor regressor__max_depth to 10\n",
      "Setting decision_tree_regressor regressor__min_samples_split to 2\n",
      "Setting random_forest_regressor regressor__max_depth to 10\n",
      "Setting random_forest_regressor regressor__n_estimators to 100\n",
      "Setting k_neighbors_regressor regressor__n_neighbors to 3\n",
      "Setting k_neighbors_regressor regressor__weights to distance\n"
     ]
    }
   ],
   "source": [
    "# Example of setting a hyperparameter for a model\n",
    "# models['k_neighbors_regressor'].set_params(regressor__n_neighbors=200)\n",
    "\n",
    "for model_name in results:\n",
    "    for param_name, param_value in results[model_name]['params'].items():\n",
    "        print(f\"Setting {model_name} {param_name} to {param_value}\")\n",
    "        models[model_name].set_params(**{param_name: param_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "<div id=\"conclusion\" />\n",
    "\n",
    "In this project we have gone over the dataset and created a model to predict the `estimated_total_comprehensive_cost` of a car crash in Austin, Texas. We have used different models and evaluated them using the test set. The best model was the Random Forest Regression with an R2 score of 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/metrics.pkl'\n",
    "Pickler(filename).save(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/models.pkl'\n",
    "Pickler(filename).save(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
